{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms,models\n",
    "import torch.nn.functional as F\n",
    "import pretrainedmodels\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GLC.data_loading.environmental_raster import PatchExtractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import GeoLifeCLEF2022Dataset\n",
    "from transform import get_train_transforms,get_valid_transforms,load_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' raster data\\nextractor_bio = PatchExtractor(DATA_PATH / \"rasters\", size=256)\\nextractor_bio.add_all_bioclimatic_rasters()\\nextractor_bio.append(\\'sndppt\\')\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DATA_PATH = DATA_PATH = Path(\"./datasets\")\n",
    "''' raster data\n",
    "extractor_bio = PatchExtractor(DATA_PATH / \"rasters\", size=256)\n",
    "extractor_bio.add_all_bioclimatic_rasters()\n",
    "extractor_bio.append('sndppt')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GeoLifeCLEF2022Dataset(DATA_PATH,subset = \"train\", \n",
    "                                 region = 'both', \n",
    "                                 patch_data = \"rgb\", \\\n",
    "                                 use_rasters = False,\\\n",
    "                                 transform = get_train_transforms())#,\\\n",
    "                                 #transform = None)#,\\\n",
    "                                 #patch_extractor = extractor_bio )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=32,shuffle = True,drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=32,shuffle = False,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_classes = 17036\n",
    "k=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import ResNet, BasicBlock\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResNetGeolife(ResNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(BasicBlock, [3, 4, 6, 3], num_classes=N_classes)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
    "\n",
    "        \n",
    "# model = ResNetGeolife().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained = True)\n",
    "model.fc = nn.Linear(2048,N_classes)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "\n",
    "\n",
    "\n",
    "def loss_fn(preds, labels,**kwargs):\n",
    "    #print (preds)\n",
    "    #print(labels)\n",
    "    loss = nn.CrossEntropyLoss(**kwargs)(preds, labels)\n",
    "    #loss = nn.BCEWithLogitsLoss()\n",
    "    return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting tau to 1.0\n"
     ]
    }
   ],
   "source": [
    "from smooth import topk\n",
    "from smooth.topk.svm import SmoothTopkSVM\n",
    "\n",
    "loss_function = SmoothTopkSVM(N_classes)\n",
    "loss_function = loss_function.cuda()\n",
    "\n",
    "def loss_fn(pred,labels):\n",
    "    loss = loss_function(pred,labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def train(model,optim,train_loader,val_loader,epochs = 2,device='cpu', patience=5):\n",
    "    last_acc = None\n",
    "    trigger_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        for idx,(inputs,target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.float()\n",
    "            \n",
    "            # normalize?\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "            \n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "\n",
    "            \n",
    "            output = model(inputs)\n",
    "            \n",
    "            # output = output.to('cpu')\n",
    "            \n",
    "\n",
    "            \n",
    "            loss = loss_fn(output,target)#,ignore_index = -1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "            \n",
    "            if idx % 50 == 0:\n",
    "                print(f\"Epoch: {epoch}, {idx}/{len(train_loader.dataset)}\")\n",
    "        \n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        \n",
    "        for idx,(inputs,target) in enumerate(val_loader):\n",
    "            inputs = inputs.float()\n",
    "            \n",
    "            # normalize?\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            output = model(inputs)\n",
    "            \n",
    "            loss = loss_fn(output,target)#,ignore_index = -1)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # sus\n",
    "            # It should have done in the top k fashion as it is validating.\n",
    "            # But it looks like it is finding the top element\n",
    "            # FIXED\n",
    "            \n",
    "            _,pred = torch.topk(output,k)\n",
    "            correct = torch.eq(target[:, None, ...], pred).any(dim=1)\n",
    "           \n",
    "            num_correct += correct.sum()\n",
    "            \n",
    "            num_examples += correct.shape[0]\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            x =  num_correct/num_examples\n",
    "            if last_acc != None:\n",
    "                if last_acc > x:\n",
    "                    trigger_time += 1\n",
    "                    print(f\"Triggered! {trigger_time}\")\n",
    "                else:\n",
    "                    trigger_time = 0\n",
    "            \n",
    "            last_acc = x\n",
    "        except ZeroDivisionError:\n",
    "            x = 0\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, '\n",
    "              'accuracy = {:.2f}'.format(epoch+1, training_loss, val_loss, x))\n",
    "        if trigger_time >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, 0/78056\n",
      "Epoch: 0, 50/78056\n",
      "Epoch: 0, 100/78056\n",
      "Epoch: 0, 150/78056\n",
      "Epoch: 0, 200/78056\n",
      "Epoch: 0, 250/78056\n",
      "Epoch: 0, 300/78056\n",
      "Epoch: 0, 350/78056\n",
      "Epoch: 0, 400/78056\n",
      "Epoch: 0, 450/78056\n",
      "Epoch: 0, 500/78056\n",
      "Epoch: 0, 550/78056\n",
      "Epoch: 0, 600/78056\n",
      "Epoch: 0, 650/78056\n",
      "Epoch: 0, 700/78056\n",
      "Epoch: 0, 750/78056\n",
      "Epoch: 0, 800/78056\n",
      "Epoch: 0, 850/78056\n",
      "Epoch: 0, 900/78056\n",
      "Epoch: 0, 950/78056\n",
      "Epoch: 0, 1000/78056\n",
      "Epoch: 0, 1050/78056\n",
      "Epoch: 0, 1100/78056\n",
      "Epoch: 0, 1150/78056\n",
      "Epoch: 0, 1200/78056\n",
      "Epoch: 0, 1250/78056\n",
      "Epoch: 0, 1300/78056\n",
      "Epoch: 0, 1350/78056\n",
      "Epoch: 0, 1400/78056\n",
      "Epoch: 0, 1450/78056\n",
      "Epoch: 0, 1500/78056\n",
      "Epoch: 0, 1550/78056\n",
      "Epoch: 0, 1600/78056\n",
      "Epoch: 0, 1650/78056\n",
      "Epoch: 0, 1700/78056\n",
      "Epoch: 0, 1750/78056\n",
      "Epoch: 0, 1800/78056\n",
      "Epoch: 0, 1850/78056\n",
      "Epoch: 0, 1900/78056\n",
      "Epoch: 0, 1950/78056\n",
      "Epoch: 0, 2000/78056\n",
      "Epoch: 0, 2050/78056\n",
      "Epoch: 0, 2100/78056\n",
      "Epoch: 0, 2150/78056\n",
      "Epoch: 0, 2200/78056\n",
      "Epoch: 0, 2250/78056\n",
      "Epoch: 0, 2300/78056\n",
      "Epoch: 0, 2350/78056\n",
      "Epoch: 0, 2400/78056\n",
      "Epoch: 0, 2450/78056\n",
      "Epoch: 0, 2500/78056\n",
      "Epoch: 0, 2550/78056\n",
      "Epoch: 0, 2600/78056\n",
      "Epoch: 0, 2650/78056\n",
      "Epoch: 0, 2700/78056\n",
      "Epoch: 0, 2750/78056\n",
      "Epoch: 0, 2800/78056\n",
      "Epoch: 0, 2850/78056\n",
      "Epoch: 0, 2900/78056\n",
      "Epoch: 0, 2950/78056\n",
      "Epoch: 0, 3000/78056\n",
      "Epoch: 0, 3050/78056\n",
      "Epoch: 0, 3100/78056\n",
      "Epoch: 0, 3150/78056\n",
      "Epoch: 0, 3200/78056\n",
      "Epoch: 0, 3250/78056\n",
      "Epoch: 0, 3300/78056\n",
      "Epoch: 0, 3350/78056\n",
      "Epoch: 0, 3400/78056\n",
      "Epoch: 0, 3450/78056\n",
      "Epoch: 0, 3500/78056\n",
      "Epoch: 0, 3550/78056\n",
      "Epoch: 0, 3600/78056\n",
      "Epoch: 0, 3650/78056\n",
      "Epoch: 0, 3700/78056\n",
      "Epoch: 0, 3750/78056\n",
      "Epoch: 0, 3800/78056\n",
      "Epoch: 0, 3850/78056\n",
      "Epoch: 0, 3900/78056\n",
      "Epoch: 0, 3950/78056\n",
      "Epoch: 0, 4000/78056\n",
      "Epoch: 0, 4050/78056\n",
      "Epoch: 0, 4100/78056\n",
      "Epoch: 0, 4150/78056\n",
      "Epoch: 0, 4200/78056\n",
      "Epoch: 0, 4250/78056\n",
      "Epoch: 0, 4300/78056\n",
      "Epoch: 0, 4350/78056\n",
      "Epoch: 0, 4400/78056\n",
      "Epoch: 0, 4450/78056\n",
      "Epoch: 0, 4500/78056\n",
      "Epoch: 0, 4550/78056\n",
      "Epoch: 0, 4600/78056\n",
      "Epoch: 0, 4650/78056\n",
      "Epoch: 0, 4700/78056\n",
      "Epoch: 0, 4750/78056\n",
      "Epoch: 0, 4800/78056\n",
      "Epoch: 0, 4850/78056\n",
      "Epoch: 1, Training Loss: 0.48, Validation Loss: 0.47, accuracy = 0.07\n",
      "Epoch: 1, 0/78056\n",
      "Epoch: 1, 50/78056\n",
      "Epoch: 1, 100/78056\n",
      "Epoch: 1, 150/78056\n",
      "Epoch: 1, 200/78056\n",
      "Epoch: 1, 250/78056\n",
      "Epoch: 1, 300/78056\n",
      "Epoch: 1, 350/78056\n",
      "Epoch: 1, 400/78056\n",
      "Epoch: 1, 450/78056\n",
      "Epoch: 1, 500/78056\n",
      "Epoch: 1, 550/78056\n",
      "Epoch: 1, 600/78056\n",
      "Epoch: 1, 650/78056\n",
      "Epoch: 1, 700/78056\n",
      "Epoch: 1, 750/78056\n",
      "Epoch: 1, 800/78056\n",
      "Epoch: 1, 850/78056\n",
      "Epoch: 1, 900/78056\n",
      "Epoch: 1, 950/78056\n",
      "Epoch: 1, 1000/78056\n",
      "Epoch: 1, 1050/78056\n",
      "Epoch: 1, 1100/78056\n",
      "Epoch: 1, 1150/78056\n",
      "Epoch: 1, 1200/78056\n",
      "Epoch: 1, 1250/78056\n",
      "Epoch: 1, 1300/78056\n",
      "Epoch: 1, 1350/78056\n",
      "Epoch: 1, 1400/78056\n",
      "Epoch: 1, 1450/78056\n",
      "Epoch: 1, 1500/78056\n",
      "Epoch: 1, 1550/78056\n",
      "Epoch: 1, 1600/78056\n",
      "Epoch: 1, 1650/78056\n",
      "Epoch: 1, 1700/78056\n",
      "Epoch: 1, 1750/78056\n",
      "Epoch: 1, 1800/78056\n",
      "Epoch: 1, 1850/78056\n",
      "Epoch: 1, 1900/78056\n",
      "Epoch: 1, 1950/78056\n",
      "Epoch: 1, 2000/78056\n",
      "Epoch: 1, 2050/78056\n",
      "Epoch: 1, 2100/78056\n",
      "Epoch: 1, 2150/78056\n",
      "Epoch: 1, 2200/78056\n",
      "Epoch: 1, 2250/78056\n",
      "Epoch: 1, 2300/78056\n",
      "Epoch: 1, 2350/78056\n",
      "Epoch: 1, 2400/78056\n",
      "Epoch: 1, 2450/78056\n",
      "Epoch: 1, 2500/78056\n",
      "Epoch: 1, 2550/78056\n",
      "Epoch: 1, 2600/78056\n",
      "Epoch: 1, 2650/78056\n",
      "Epoch: 1, 2700/78056\n",
      "Epoch: 1, 2750/78056\n",
      "Epoch: 1, 2800/78056\n",
      "Epoch: 1, 2850/78056\n",
      "Epoch: 1, 2900/78056\n",
      "Epoch: 1, 2950/78056\n",
      "Epoch: 1, 3000/78056\n",
      "Epoch: 1, 3050/78056\n",
      "Epoch: 1, 3100/78056\n",
      "Epoch: 1, 3150/78056\n",
      "Epoch: 1, 3200/78056\n",
      "Epoch: 1, 3250/78056\n",
      "Epoch: 1, 3300/78056\n",
      "Epoch: 1, 3350/78056\n",
      "Epoch: 1, 3400/78056\n",
      "Epoch: 1, 3450/78056\n",
      "Epoch: 1, 3500/78056\n",
      "Epoch: 1, 3550/78056\n",
      "Epoch: 1, 3600/78056\n",
      "Epoch: 1, 3650/78056\n",
      "Epoch: 1, 3700/78056\n",
      "Epoch: 1, 3750/78056\n",
      "Epoch: 1, 3800/78056\n",
      "Epoch: 1, 3850/78056\n",
      "Epoch: 1, 3900/78056\n",
      "Epoch: 1, 3950/78056\n",
      "Epoch: 1, 4000/78056\n",
      "Epoch: 1, 4050/78056\n",
      "Epoch: 1, 4100/78056\n",
      "Epoch: 1, 4150/78056\n",
      "Epoch: 1, 4200/78056\n",
      "Epoch: 1, 4250/78056\n",
      "Epoch: 1, 4300/78056\n",
      "Epoch: 1, 4350/78056\n",
      "Epoch: 1, 4400/78056\n",
      "Epoch: 1, 4450/78056\n",
      "Epoch: 1, 4500/78056\n",
      "Epoch: 1, 4550/78056\n",
      "Epoch: 1, 4600/78056\n",
      "Epoch: 1, 4650/78056\n",
      "Epoch: 1, 4700/78056\n",
      "Epoch: 1, 4750/78056\n",
      "Epoch: 1, 4800/78056\n",
      "Epoch: 1, 4850/78056\n",
      "Epoch: 2, Training Loss: 0.45, Validation Loss: 0.46, accuracy = 0.08\n",
      "Epoch: 2, 0/78056\n",
      "Epoch: 2, 50/78056\n",
      "Epoch: 2, 100/78056\n",
      "Epoch: 2, 150/78056\n",
      "Epoch: 2, 200/78056\n",
      "Epoch: 2, 250/78056\n",
      "Epoch: 2, 300/78056\n",
      "Epoch: 2, 350/78056\n",
      "Epoch: 2, 400/78056\n",
      "Epoch: 2, 450/78056\n",
      "Epoch: 2, 500/78056\n",
      "Epoch: 2, 550/78056\n",
      "Epoch: 2, 600/78056\n",
      "Epoch: 2, 650/78056\n",
      "Epoch: 2, 700/78056\n",
      "Epoch: 2, 750/78056\n",
      "Epoch: 2, 800/78056\n",
      "Epoch: 2, 850/78056\n",
      "Epoch: 2, 900/78056\n",
      "Epoch: 2, 950/78056\n",
      "Epoch: 2, 1000/78056\n",
      "Epoch: 2, 1050/78056\n",
      "Epoch: 2, 1100/78056\n",
      "Epoch: 2, 1150/78056\n",
      "Epoch: 2, 1200/78056\n",
      "Epoch: 2, 1250/78056\n",
      "Epoch: 2, 1300/78056\n",
      "Epoch: 2, 1350/78056\n",
      "Epoch: 2, 1400/78056\n",
      "Epoch: 2, 1450/78056\n",
      "Epoch: 2, 1500/78056\n",
      "Epoch: 2, 1550/78056\n",
      "Epoch: 2, 1600/78056\n",
      "Epoch: 2, 1650/78056\n",
      "Epoch: 2, 1700/78056\n",
      "Epoch: 2, 1750/78056\n",
      "Epoch: 2, 1800/78056\n",
      "Epoch: 2, 1850/78056\n",
      "Epoch: 2, 1900/78056\n",
      "Epoch: 2, 1950/78056\n",
      "Epoch: 2, 2000/78056\n",
      "Epoch: 2, 2050/78056\n",
      "Epoch: 2, 2100/78056\n",
      "Epoch: 2, 2150/78056\n",
      "Epoch: 2, 2200/78056\n",
      "Epoch: 2, 2250/78056\n",
      "Epoch: 2, 2300/78056\n",
      "Epoch: 2, 2350/78056\n"
     ]
    }
   ],
   "source": [
    "train(model.to(device), optimizer, train_loader, val_loader, epochs=100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './torchvision_resnet50.bin'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNetGeolife()\n",
    "model.load_state_dict(torch.load('./torchvision_resnet50.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,val_loader):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_examples = 0\n",
    "    \n",
    "    for inputs,target in val_loader:\n",
    "        inputs = inputs.float()\n",
    "            \n",
    "        # normalize?\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "        inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "        output = model(inputs)\n",
    "        # sus\n",
    "        # It should have done in the top k fashion as it is validating.\n",
    "        # But it looks like it is finding the top element\n",
    "\n",
    "        _,pred = torch.topk(output,k)\n",
    "        # print(pred,target)\n",
    "        correct = torch.eq(target[:, None, ...], pred).any(dim=1)\n",
    "        \n",
    "        num_correct += correct.sum().item()\n",
    "\n",
    "        num_examples += correct.shape[0]\n",
    "    print('accuracy: {:.2f}'.format(num_correct/num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.10\n"
     ]
    }
   ],
   "source": [
    "validate(model.to(device),val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_740763/1878049818.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = GeoLifeCLEF2022Dataset(DATA_PATH,subset = \"test\", \n",
    "                                 region = 'both', \n",
    "                                 patch_data = 'landcover', \\\n",
    "                                 use_rasters = True,\\\n",
    "                                 transform = None,\\\n",
    "                                 patch_extractor = extractor_bio\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference (model, dl):\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "    PREDS = []\n",
    "    #LABELS = []\n",
    "    model.eval()\n",
    "    # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(iter(dl)):\n",
    "            # Get the input features , and put them on the GPU\n",
    "            inputs = data[0]\n",
    "            inputs = inputs.float()\n",
    "            # Normalize the inputs\n",
    "            #inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            #inputs = (inputs - inputs_m) / inputs_s\n",
    "            #print (inputs.shape)\n",
    "            # inputs = np.repeat(inputs[..., np.newaxis], 3, -1)\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "            #print (inputs.shape)\n",
    "            #if inputs.size(1) > 3:\n",
    "            # inputs = inputs.permute(0,3, 1,2)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            PREDS.append(prediction.view(-1).cpu().detach().numpy())\n",
    "\n",
    "\n",
    "\n",
    "    PREDS = np.concatenate(PREDS)\n",
    "   # LABELS = np.concatenate(LABELS)\n",
    "\n",
    "#     preds_df = pd.DataFrame({'song_id':LABELS, 'genre_id':PREDS})\n",
    "    return (PREDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 w/ PyTorch",
   "language": "python",
   "name": "py39torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
