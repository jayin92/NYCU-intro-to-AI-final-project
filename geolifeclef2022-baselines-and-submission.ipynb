{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035032,
     "end_time": "2022-02-23T11:38:04.769078",
     "exception": false,
     "start_time": "2022-02-23T11:38:04.734046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook presents some code to compute some basic baselines.\n",
    "\n",
    "In particular, it shows how to:\n",
    "1. Use the provided validation set\n",
    "2. Compute the top-30 metric\n",
    "3. Save the predictions on the test in the right format for submission"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    },
    "papermill": {
     "duration": 3.39579,
     "end_time": "2022-02-23T11:38:08.198110",
     "exception": false,
     "start_time": "2022-02-23T11:38:04.802320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A git directory for 'GLC' is found locally with remote(s):\n",
      "  origin\thttps://github.com/maximiliense/GLC\n",
      "If you want to reuse this local git directory instead of cloning again from\n",
      "  https://github.com/maximiliense/GLC\n",
      "use the '--force' option. If the local git directory is not the correct repo\n",
      "or you are unsure what this means choose another name with the '--name' option.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Change this path to adapt to where you downloaded the data\n",
    "DATA_PATH = Path(\"./datasets\")\n",
    "\n",
    "# Create the path to save submission files\n",
    "SUBMISSION_PATH = Path(\"submissions\")\n",
    "os.makedirs(SUBMISSION_PATH, exist_ok=True)\n",
    "\n",
    "# Clone the GitHub repository\n",
    "!git submodule add https://github.com/maximiliense/GLC GLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03902,
     "end_time": "2022-02-23T11:38:08.277101",
     "exception": false,
     "start_time": "2022-02-23T11:38:08.238081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also load the official metric, top-30 error rate, for which we provide efficient implementations:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    },
    "papermill": {
     "duration": 0.050363,
     "end_time": "2022-02-23T11:38:08.366495",
     "exception": false,
     "start_time": "2022-02-23T11:38:08.316132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'GLC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2538185/719194372.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mGLC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtop_30_error_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_30_error_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'GLC'"
     ]
    }
   ],
   "source": [
    "from GLC.metrics import top_30_error_rate\n",
    "help(top_30_error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:34.840459Z",
     "start_time": "2022-02-15T15:34:34.833489Z"
    },
    "papermill": {
     "duration": 0.049132,
     "end_time": "2022-02-23T11:38:08.459831",
     "exception": false,
     "start_time": "2022-02-23T11:38:08.410699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function top_k_error_rate_from_sets in module GLC.metrics:\n",
      "\n",
      "top_k_error_rate_from_sets(y_true: 'npt.ArrayLike', s_pred: 'npt.ArrayLike') -> 'float'\n",
      "    Computes the top-k error rate from predicted sets.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true: 1d array-like, [n_samples]\n",
      "        True labels.\n",
      "    s_pred: 2d array-like, [n_samples, k]\n",
      "        Previously computed top-k sets for each sample.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    float:\n",
      "        Error rate value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from GLC.metrics import top_k_error_rate_from_sets\n",
    "help(top_k_error_rate_from_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039781,
     "end_time": "2022-02-23T11:38:08.540418",
     "exception": false,
     "start_time": "2022-02-23T11:38:08.500637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For submissions, we will also need to predict the top-30 sets for which we also provide an efficient implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:34.850192Z",
     "start_time": "2022-02-15T15:34:34.843048Z"
    },
    "papermill": {
     "duration": 0.049804,
     "end_time": "2022-02-23T11:38:08.630829",
     "exception": false,
     "start_time": "2022-02-23T11:38:08.581025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function predict_top_30_set in module GLC.metrics:\n",
      "\n",
      "predict_top_30_set(y_score: 'npt.ArrayLike') -> 'npt.NDArray'\n",
      "    Predicts the top-30 sets from scores.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_score: 2d array-like, [n_samples, n_classes]\n",
      "        Scores for each sample and label.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    2d array, [n_samples, 30]:\n",
      "        Predicted top-30 sets for each sample.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Complexity: :math:`O( n_\\text{samples} \\times n_\\text{classes} )`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from GLC.metrics import predict_top_30_set\n",
    "help(predict_top_30_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040366,
     "end_time": "2022-02-23T11:38:08.711849",
     "exception": false,
     "start_time": "2022-02-23T11:38:08.671483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also provide an utility function to generate submission files in the right format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 0.050173,
     "end_time": "2022-02-23T11:38:08.803169",
     "exception": false,
     "start_time": "2022-02-23T11:38:08.752996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function generate_submission_file in module GLC.submission:\n",
      "\n",
      "generate_submission_file(filename: 'str', observation_ids: 'npt.ArrayLike', s_pred: 'list[Iterable]') -> 'None'\n",
      "    Generate submission file for Kaggle\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filename : string\n",
      "        Submission filename.\n",
      "    observation_ids : 1d array-like\n",
      "        Test observations ids\n",
      "    s_pred : list of 1d array-like\n",
      "        Set predictions for test observations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from GLC.submission import generate_submission_file\n",
    "help(generate_submission_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041185,
     "end_time": "2022-02-23T11:38:08.886304",
     "exception": false,
     "start_time": "2022-02-23T11:38:08.845119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Observation data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041447,
     "end_time": "2022-02-23T11:38:08.968788",
     "exception": false,
     "start_time": "2022-02-23T11:38:08.927341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We first need to load the observation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:35.686811Z",
     "start_time": "2022-02-15T15:34:34.851926Z"
    },
    "papermill": {
     "duration": 2.293277,
     "end_time": "2022-02-23T11:38:11.302480",
     "exception": false,
     "start_time": "2022-02-23T11:38:09.009203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_obs_fr = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs = pd.concat((df_obs_fr, df_obs_us))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040901,
     "end_time": "2022-02-23T11:38:11.387241",
     "exception": false,
     "start_time": "2022-02-23T11:38:11.346340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then, we retrieve the train/val split provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:36.13279Z",
     "start_time": "2022-02-15T15:34:35.688156Z"
    },
    "papermill": {
     "duration": 1.049286,
     "end_time": "2022-02-23T11:38:12.478234",
     "exception": false,
     "start_time": "2022-02-23T11:38:11.428948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size: 40080 (2.5% of train observations)\n"
     ]
    }
   ],
   "source": [
    "obs_id_train = df_obs.index[df_obs[\"subset\"] == \"train\"].values\n",
    "obs_id_val = df_obs.index[df_obs[\"subset\"] == \"val\"].values\n",
    "\n",
    "y_train = df_obs.loc[obs_id_train][\"species_id\"].values\n",
    "y_val = df_obs.loc[obs_id_val][\"species_id\"].values\n",
    "\n",
    "n_val = len(obs_id_val)\n",
    "print(\"Validation set size: {} ({:.1%} of train observations)\".format(n_val, n_val / len(df_obs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042843,
     "end_time": "2022-02-23T11:38:12.564680",
     "exception": false,
     "start_time": "2022-02-23T11:38:12.521837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also load the observation data for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:36.16918Z",
     "start_time": "2022-02-15T15:34:36.134721Z"
    },
    "papermill": {
     "duration": 0.131649,
     "end_time": "2022-02-23T11:38:12.742334",
     "exception": false,
     "start_time": "2022-02-23T11:38:12.610685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for testing: 36421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10782781</th>\n",
       "      <td>43.601788</td>\n",
       "      <td>6.940195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10364138</th>\n",
       "      <td>46.241711</td>\n",
       "      <td>0.683586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10692017</th>\n",
       "      <td>45.181095</td>\n",
       "      <td>1.533459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10222322</th>\n",
       "      <td>46.938450</td>\n",
       "      <td>5.298678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10241950</th>\n",
       "      <td>45.017433</td>\n",
       "      <td>0.960736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 latitude  longitude\n",
       "observation_id                      \n",
       "10782781        43.601788   6.940195\n",
       "10364138        46.241711   0.683586\n",
       "10692017        45.181095   1.533459\n",
       "10222322        46.938450   5.298678\n",
       "10241950        45.017433   0.960736"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obs_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "\n",
    "df_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n",
    "\n",
    "obs_id_test = df_obs_test.index.values\n",
    "\n",
    "print(\"Number of observations for testing: {}\".format(len(df_obs_test)))\n",
    "\n",
    "df_obs_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041424,
     "end_time": "2022-02-23T11:38:12.826710",
     "exception": false,
     "start_time": "2022-02-23T11:38:12.785286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sample submission file\n",
    "\n",
    "In this section, we will demonstrate how to generate the sample submission file provided.\n",
    "\n",
    "To do so, we will use the function `generate_submission_file` from `GLC.submission`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041929,
     "end_time": "2022-02-23T11:38:12.911064",
     "exception": false,
     "start_time": "2022-02-23T11:38:12.869135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The sample submission consists in always predicting the first 30 species for all the test observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:36.18507Z",
     "start_time": "2022-02-15T15:34:36.176395Z"
    },
    "papermill": {
     "duration": 0.058245,
     "end_time": "2022-02-23T11:38:13.011239",
     "exception": false,
     "start_time": "2022-02-23T11:38:12.952994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29]]\n",
      "Int64Index([10782781, 10364138, 10692017, 10222322, 10241950, 10384270,\n",
      "            10748824, 10651479, 10101172, 10023350,\n",
      "            ...\n",
      "            22067172, 22067308, 22067620, 22067654, 22067674, 22067746,\n",
      "            22067972, 22068007, 22068076, 22068082],\n",
      "           dtype='int64', name='observation_id', length=36421)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "first_30_species = np.arange(30)\n",
    "print(first_30_species[None])\n",
    "s_pred = np.tile(first_30_species[None], (len(df_obs_test), 1))\n",
    "print(df_obs_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047926,
     "end_time": "2022-02-23T11:38:13.102587",
     "exception": false,
     "start_time": "2022-02-23T11:38:13.054661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can then generate the associated submission file using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:36.873681Z",
     "start_time": "2022-02-15T15:34:36.188032Z"
    },
    "papermill": {
     "duration": 1.242551,
     "end_time": "2022-02-23T11:38:14.388303",
     "exception": false,
     "start_time": "2022-02-23T11:38:13.145752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_submission_file(SUBMISSION_PATH / \"sample_submission.csv\", df_obs_test.index, s_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043178,
     "end_time": "2022-02-23T11:38:14.474094",
     "exception": false,
     "start_time": "2022-02-23T11:38:14.430916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Constant baseline: 30 most observed species\n",
    "\n",
    "The first baseline consists in predicting the 30 most observed species on the train set which corresponds exactly to the \"Top-30 most present species\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:37.030364Z",
     "start_time": "2022-02-15T15:34:36.875285Z"
    },
    "papermill": {
     "duration": 0.349753,
     "end_time": "2022-02-23T11:38:14.868950",
     "exception": false,
     "start_time": "2022-02-23T11:38:14.519197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "species_distribution = df_obs.loc[obs_id_train][\"species_id\"].value_counts(normalize=True)\n",
    "top_30_most_observed = species_distribution.index.values[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045348,
     "end_time": "2022-02-23T11:38:14.957126",
     "exception": false,
     "start_time": "2022-02-23T11:38:14.911778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As expected, it does not perform very well on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:37.043069Z",
     "start_time": "2022-02-15T15:34:37.032104Z"
    },
    "papermill": {
     "duration": 0.069408,
     "end_time": "2022-02-23T11:38:15.071904",
     "exception": false,
     "start_time": "2022-02-23T11:38:15.002496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-30 error rate: 93.5%\n"
     ]
    }
   ],
   "source": [
    "s_pred = np.tile(top_30_most_observed[None], (n_val, 1))\n",
    "score = top_k_error_rate_from_sets(y_val, s_pred)\n",
    "print(\"Top-30 error rate: {:.1%}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04233,
     "end_time": "2022-02-23T11:38:15.159349",
     "exception": false,
     "start_time": "2022-02-23T11:38:15.117019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will however generate the associated submission file on the test using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:37.762255Z",
     "start_time": "2022-02-15T15:34:37.044524Z"
    },
    "papermill": {
     "duration": 1.379623,
     "end_time": "2022-02-23T11:38:16.584052",
     "exception": false,
     "start_time": "2022-02-23T11:38:15.204429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute baseline on the test set\n",
    "n_test = len(df_obs_test)\n",
    "s_pred = np.tile(top_30_most_observed[None], (n_test, 1))\n",
    "\n",
    "# Generate the submission file\n",
    "generate_submission_file(SUBMISSION_PATH / \"constant_top_30_most_present_species_baseline.csv\", df_obs_test.index, s_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044111,
     "end_time": "2022-02-23T11:38:16.672022",
     "exception": false,
     "start_time": "2022-02-23T11:38:16.627911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Random forest on environmental vectors\n",
    "\n",
    "A classical approach in ecology is to train Random Forests on environmental vectors.\n",
    "\n",
    "We show here how to do so using [scikit-learn](https://scikit-learn.org/).\n",
    "\n",
    "We start by loading the environmental vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:45.731902Z",
     "start_time": "2022-02-15T15:34:37.764022Z"
    },
    "papermill": {
     "duration": 15.533405,
     "end_time": "2022-02-23T11:38:32.249196",
     "exception": false,
     "start_time": "2022-02-23T11:38:16.715791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_env = pd.read_csv(DATA_PATH / \"pre-extracted\" / \"environmental_vectors.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "\n",
    "X_train = df_env.loc[obs_id_train].values\n",
    "X_val = df_env.loc[obs_id_val].values\n",
    "X_test = df_env.loc[obs_id_test].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042813,
     "end_time": "2022-02-23T11:38:32.335476",
     "exception": false,
     "start_time": "2022-02-23T11:38:32.292663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then, we need to handle properly the missing values.\n",
    "\n",
    "For instance, using `SimpleImputer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:34:46.705147Z",
     "start_time": "2022-02-15T15:34:45.734104Z"
    },
    "papermill": {
     "duration": 2.073617,
     "end_time": "2022-02-23T11:38:34.452173",
     "exception": false,
     "start_time": "2022-02-23T11:38:32.378556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    strategy=\"constant\",\n",
    "    fill_value=np.finfo(np.float32).min,\n",
    ")\n",
    "imp.fit(X_train)\n",
    "\n",
    "X_train = imp.transform(X_train)\n",
    "X_val = imp.transform(X_val)\n",
    "X_test = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041619,
     "end_time": "2022-02-23T11:38:34.536881",
     "exception": false,
     "start_time": "2022-02-23T11:38:34.495262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now start training our Random Forest (as there are a lot of observations, over 1.8M, this can take a while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:37:23.045384Z",
     "start_time": "2022-02-15T15:34:46.706534Z"
    },
    "papermill": {
     "duration": 390.268314,
     "end_time": "2022-02-23T11:45:04.847336",
     "exception": false,
     "start_time": "2022-02-23T11:38:34.579022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1747563/673815265.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/env/pytorch/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    442\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/pytorch/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/pytorch/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "est = RandomForestClassifier(n_estimators=100, max_depth=16, n_jobs=64)\n",
    "est.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044758,
     "end_time": "2022-02-23T11:45:04.938001",
     "exception": false,
     "start_time": "2022-02-23T11:45:04.893243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As there are a lot of classes (over 17K), we need to be cautious when predicting the scores of the model.\n",
    "\n",
    "This can easily take more than 5Go on the validation set.\n",
    "\n",
    "For this reason, we will be predict the top-30 sets by batches using the following generic function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:37:23.06365Z",
     "start_time": "2022-02-15T15:37:23.051514Z"
    },
    "papermill": {
     "duration": 0.056377,
     "end_time": "2022-02-23T11:45:05.040287",
     "exception": false,
     "start_time": "2022-02-23T11:45:04.983910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_predict(predict_func, X, batch_size=1024):\n",
    "    res = predict_func(X[:1])\n",
    "    n_samples, n_outputs, dtype = X.shape[0], res.shape[1], res.dtype\n",
    "    \n",
    "    preds = np.empty((n_samples, n_outputs), dtype=dtype)\n",
    "    \n",
    "    for i in range(0, len(X), batch_size):\n",
    "        X_batch = X[i:i+batch_size]\n",
    "        preds[i:i+batch_size] = predict_func(X_batch)\n",
    "            \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044842,
     "end_time": "2022-02-23T11:45:05.130752",
     "exception": false,
     "start_time": "2022-02-23T11:45:05.085910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can know compute the top-30 error rate on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:38:04.919835Z",
     "start_time": "2022-02-15T15:37:23.068792Z"
    },
    "papermill": {
     "duration": 50.84775,
     "end_time": "2022-02-23T11:45:56.023763",
     "exception": false,
     "start_time": "2022-02-23T11:45:05.176013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_func(X):\n",
    "    y_score = est.predict_proba(X)\n",
    "    s_pred = predict_top_30_set(y_score)\n",
    "    return s_pred\n",
    "\n",
    "s_val = batch_predict(predict_func, X_val, batch_size=1024)\n",
    "score_val = top_k_error_rate_from_sets(y_val, s_val)\n",
    "print(\"Top-30 error rate: {:.1%}\".format(score_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044977,
     "end_time": "2022-02-23T11:45:56.112606",
     "exception": false,
     "start_time": "2022-02-23T11:45:56.067629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now predict the top-30 sets on the test data and save them in a submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T15:38:44.086269Z",
     "start_time": "2022-02-15T15:38:04.921407Z"
    },
    "papermill": {
     "duration": 44.670961,
     "end_time": "2022-02-23T11:46:40.827720",
     "exception": false,
     "start_time": "2022-02-23T11:45:56.156759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute baseline on the test set\n",
    "s_pred = batch_predict(predict_func, X_test, batch_size=1024)\n",
    "\n",
    "# Generate the submission file\n",
    "generate_submission_file(SUBMISSION_PATH / \"random_forest_on_environmental_vectors.csv\", df_obs_test.index, s_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04367,
     "end_time": "2022-02-23T11:46:40.917333",
     "exception": false,
     "start_time": "2022-02-23T11:46:40.873663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Note that the baseline appearing on the leaderboard is a similar Random Forest of 100 trees and a max depth of 16.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.043938,
     "end_time": "2022-02-23T11:46:41.004884",
     "exception": false,
     "start_time": "2022-02-23T11:46:40.960946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 w/ PyTorch",
   "language": "python",
   "name": "py39torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 527.730442,
   "end_time": "2022-02-23T11:46:42.367195",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-23T11:37:54.636753",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
